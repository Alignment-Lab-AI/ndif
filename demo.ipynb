{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install client library (you may need to restart your kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///disk/u/jfiottok/wd/engine/client\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /disk/u/jfiottok/miniconda3/envs/temp/lib/python3.10/site-packages (from engine==1.0) (6.0)\n",
      "Requirement already satisfied: pydantic in /disk/u/jfiottok/miniconda3/envs/temp/lib/python3.10/site-packages (from engine==1.0) (1.10.7)\n",
      "Requirement already satisfied: shortuuid in /disk/u/jfiottok/miniconda3/envs/temp/lib/python3.10/site-packages (from engine==1.0) (1.0.11)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /disk/u/jfiottok/miniconda3/envs/temp/lib/python3.10/site-packages (from pydantic->engine==1.0) (4.4.0)\n",
      "Installing collected packages: engine\n",
      "  Attempting uninstall: engine\n",
      "    Found existing installation: engine 1.0\n",
      "    Uninstalling engine-1.0:\n",
      "      Successfully uninstalled engine-1.0\n",
      "  Running setup.py develop for engine\n",
      "Successfully installed engine-1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -e client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This will give you you the `engine` module\n",
    "##### this exposes `engine.get_info`, `engine.submit`, and `engine.retrieve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `engine.get_info` returns a dictionary informing you of the currently loaded model as well as parameters about it, such as layer naming formats which will help you specify the particualar components of the model you want to access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attn_module_name_format': 'model.layers.{}.self_attn',\n",
       " 'layer_name_format': 'model.layers.{}',\n",
       " 'max_seq_length': 2048,\n",
       " 'mlp_module_name_format': 'model.layers.{}.mlp',\n",
       " 'model_name': 'LLaMa-65b',\n",
       " 'n_attn_head': 52,\n",
       " 'n_embd': 6656,\n",
       " 'n_layer': 60}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = engine.get_info()\n",
    "info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `engine.submit(...)` submits your job request to the server. You can see the format and types of the request like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Request',\n",
       " 'type': 'object',\n",
       " 'properties': {'job_id': {'title': 'Job Id', 'type': 'string'},\n",
       "  'prompt': {'title': 'Prompt',\n",
       "   'anyOf': [{'type': 'string'},\n",
       "    {'type': 'array', 'items': {'type': 'string'}}]},\n",
       "  'max_new_tokens': {'title': 'Max New Tokens',\n",
       "   'default': 1,\n",
       "   'type': 'integer'},\n",
       "  'get_answers': {'title': 'Get Answers', 'default': False, 'type': 'boolean'},\n",
       "  'top_k': {'title': 'Top K', 'default': 1, 'type': 'integer'},\n",
       "  'generate_greedy': {'title': 'Generate Greedy',\n",
       "   'default': True,\n",
       "   'type': 'boolean'},\n",
       "  'activation_requests': {'title': 'Activation Requests',\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/ActivationRequest'}}},\n",
       " 'required': ['job_id', 'prompt'],\n",
       " 'definitions': {'ActivationRequest': {'title': 'ActivationRequest',\n",
       "   'type': 'object',\n",
       "   'properties': {'final_output': {'title': 'Final Output',\n",
       "     'default': True,\n",
       "     'type': 'boolean'},\n",
       "    'layers': {'title': 'Layers',\n",
       "     'type': 'array',\n",
       "     'items': {'type': 'string'}},\n",
       "    'intervention': {'title': 'Intervention', 'type': 'string'}}}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.models.submit.Request.schema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Or by visiting out api documentation at [https://ndif.baulab.us/api/docs](https://ndif.baulab.us/api/docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this example request, were going to:\n",
    "\n",
    "<ul>\n",
    "  <li>Process a couple of prompts like, \"Michael Jordan plays the sport of\"</li>\n",
    "  <li>Have ten predicted tokens returned to us per prompt</li>\n",
    "  <li>Have the top five most likely tokens returned to us, not just the top 1</li>\n",
    "  <li>Finally, were going to use the format we recieved from the get_info() function, to specify that we also want the activations at a few layers in the model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 2023-04-14 17:06:35,628 - => Submitting request...\n",
      "INFO: 2023-04-14 17:06:35,641 - => Successfully submitted job 'nikFcJHzgRi2q8D5TFVtEB'\n",
      "INFO: 2023-04-14 17:06:35,643 - => Dumped request for job 'nikFcJHzgRi2q8D5TFVtEB' to /disk/u/jfiottok/wd/engine/jobs/nikFcJHzgRi2q8D5TFVtEB\n"
     ]
    }
   ],
   "source": [
    "response = engine.submit(\n",
    "    prompt = [\n",
    "        \"Michael Jordan plays the sport of\",\n",
    "        \"The Space Needle is located in the city of\"\n",
    "    ],\n",
    "    max_new_tokens= 10,\n",
    "    get_answers= True,\n",
    "    top_k = 5,\n",
    "    activation_requests = [\n",
    "        {\n",
    "            'layers':  [info[\"layer_name_format\"].format(l) for l in range(5, 10)]\n",
    "\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The server will recieve our request, and return a status (Which we hope will say that it received our request with no problem), as well as the job id identifying our request. This is loaded into the `engine.models.result.Result` model. The request we submited will be saved to our local `./jobs` directory for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job has been recieved is is waiting approval\n",
      "JobStatus.RECIVED\n",
      "nikFcJHzgRi2q8D5TFVtEB\n"
     ]
    }
   ],
   "source": [
    "print(response.description)\n",
    "print(response.status)\n",
    "print(response.job_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now to retrieve what we asked for, we call `engine.retrieve(<job_id>)` using the job_id recieved. This too will return an `engine.models.result.Result` object, and assuming your request has been approved and processed, the `data` field will be populated. \n",
    "\n",
    "###### This result will also be stored to disk in the same directory as the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 2023-04-14 17:11:26,369 - => Retrieving job 'nikFcJHzgRi2q8D5TFVtEB'...\n",
      "INFO: 2023-04-14 17:11:26,381 - => Retrieved job 'nikFcJHzgRi2q8D5TFVtEB'\n",
      "INFO: 2023-04-14 17:11:26,382 - => Dumped response for job 'nikFcJHzgRi2q8D5TFVtEB' to /disk/u/jfiottok/wd/engine/jobs/nikFcJHzgRi2q8D5TFVtEB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(job_id='nikFcJHzgRi2q8D5TFVtEB', status=<JobStatus.ERROR: 'ERROR'>, timestamp=datetime.datetime(2023, 4, 14, 21, 6, 36, 551911), description='Your job errored out', data=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = engine.retrieve(response.job_id)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your job has been completed'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['job_id', 'status', 'timestamp', 'description', 'data'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_text': ModelField(name='generated_text', type=List[str], required=True),\n",
       " 'answer': ModelField(name='answer', type=List[Answer], required=True),\n",
       " 'input_tokenized': ModelField(name='input_tokenized', type=Optional[list], required=False, default=None),\n",
       " 'generated_tokens': ModelField(name='generated_tokens', type=list, required=True),\n",
       " 'activations': ModelField(name='activations', type=Optional[Mapping[str, list[list[list[float]]]]], required=False, default=None)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.data[0].__fields__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['transformer.h.5', 'transformer.h.6', 'transformer.h.7', 'transformer.h.8', 'transformer.h.9'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.data[0].activations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt =  [\"Michael Jordan plays the sport of basketball, but he's not a basketball player.\"]\n",
      "input_tokenized =  [['Michael', 13256], [' Jordan', 8078], [' plays', 5341], [' the', 262], [' sport', 6332], [' of', 286]]\n",
      "answer =  [Answer(top_token=' basketball', candidates=[Candidate(token=' basketball', token_id=9669, p=0.8828), Candidate(token=' football', token_id=4346, p=0.0157), Candidate(token=' golf', token_id=13126, p=0.0138), Candidate(token=' hoops', token_id=46730, p=0.0089), Candidate(token=' Basketball', token_id=25911, p=0.0056)])]\n",
      "generated_tokens =  [[[{'token': ' basketball', 'id': 9669, 'p': 0.8828125}, {'token': ' football', 'id': 4346, 'p': 0.0156707763671875}, {'token': ' golf', 'id': 13126, 'p': 0.01383209228515625}, {'token': ' hoops', 'id': 46730, 'p': 0.00893402099609375}, {'token': ' Basketball', 'id': 25911, 'p': 0.005588531494140625}], [{'token': ',', 'id': 11, 'p': 0.11767578125}, {'token': ' with', 'id': 351, 'p': 0.09161376953125}, {'token': '.', 'id': 13, 'p': 0.09161376953125}, {'token': ' in', 'id': 287, 'p': 0.08087158203125}, {'token': ' and', 'id': 290, 'p': 0.06298828125}], [{'token': ' but', 'id': 475, 'p': 0.247314453125}, {'token': ' and', 'id': 290, 'p': 0.192626953125}, {'token': ' so', 'id': 523, 'p': 0.037933349609375}, {'token': ' which', 'id': 543, 'p': 0.033477783203125}, {'token': ' he', 'id': 339, 'p': 0.03143310546875}], [{'token': ' he', 'id': 339, 'p': 0.366455078125}, {'token': ' his', 'id': 465, 'p': 0.059814453125}, {'token': ' it', 'id': 340, 'p': 0.041107177734375}, {'token': ' not', 'id': 407, 'p': 0.032012939453125}, {'token': ' the', 'id': 262, 'p': 0.02825927734375}], [{'token': \"'s\", 'id': 338, 'p': 0.29541015625}, {'token': ' also', 'id': 635, 'p': 0.10870361328125}, {'token': ' is', 'id': 318, 'p': 0.07952880859375}, {'token': ' doesn', 'id': 1595, 'p': 0.06591796875}, {'token': ' has', 'id': 468, 'p': 0.042572021484375}], [{'token': ' not', 'id': 407, 'p': 0.246337890625}, {'token': ' also', 'id': 635, 'p': 0.2314453125}, {'token': ' a', 'id': 257, 'p': 0.054962158203125}, {'token': ' never', 'id': 1239, 'p': 0.035491943359375}, {'token': ' more', 'id': 517, 'p': 0.01479339599609375}], [{'token': ' a', 'id': 257, 'p': 0.1728515625}, {'token': ' the', 'id': 262, 'p': 0.143310546875}, {'token': ' just', 'id': 655, 'p': 0.056121826171875}, {'token': ' really', 'id': 1107, 'p': 0.04107666015625}, {'token': ' an', 'id': 281, 'p': 0.0300445556640625}], [{'token': ' basketball', 'id': 9669, 'p': 0.193603515625}, {'token': ' professional', 'id': 4708, 'p': 0.043212890625}, {'token': ' big', 'id': 1263, 'p': 0.026214599609375}, {'token': ' fan', 'id': 4336, 'p': 0.0246124267578125}, {'token': ' star', 'id': 3491, 'p': 0.0246124267578125}], [{'token': ' player', 'id': 2137, 'p': 0.83251953125}, {'token': ' fan', 'id': 4336, 'p': 0.035430908203125}, {'token': ' coach', 'id': 3985, 'p': 0.02288818359375}, {'token': ' guy', 'id': 3516, 'p': 0.02020263671875}, {'token': ' person', 'id': 1048, 'p': 0.011505126953125}], [{'token': '.', 'id': 13, 'p': 0.67578125}, {'token': ',', 'id': 11, 'p': 0.06689453125}, {'token': ',\"', 'id': 553, 'p': 0.0609130859375}, {'token': '.\"', 'id': 526, 'p': 0.0306243896484375}, {'token': ';', 'id': 26, 'p': 0.01800537109375}]]]\n",
      "activations\n",
      "     transformer.h.5 : torch.Size([1, 6, 1024])\n",
      "     transformer.h.6 : torch.Size([1, 6, 1024])\n",
      "     transformer.h.7 : torch.Size([1, 6, 1024])\n",
      "     transformer.h.8 : torch.Size([1, 6, 1024])\n",
      "     transformer.h.9 : torch.Size([1, 6, 1024])\n",
      "\n",
      "txt =  ['The Space Needle is located in the city of Seattle, Washington. It is the largest public park']\n",
      "input_tokenized =  [['The', 464], [' Space', 4687], [' Need', 10664], ['le', 293], [' is', 318], [' located', 5140], [' in', 287], [' the', 262], [' city', 1748], [' of', 286]]\n",
      "answer =  [Answer(top_token=' Seattle', candidates=[Candidate(token=' Seattle', token_id=7312, p=0.0474), Candidate(token=' San', token_id=2986, p=0.0288), Candidate(token=' New', token_id=968, p=0.0224), Candidate(token=' Chicago', token_id=4842, p=0.0198), Candidate(token=' Los', token_id=5401, p=0.0186)])]\n",
      "generated_tokens =  [[[{'token': ' Seattle', 'id': 7312, 'p': 0.04742431640625}, {'token': ' San', 'id': 2986, 'p': 0.0287628173828125}, {'token': ' New', 'id': 968, 'p': 0.02239990234375}, {'token': ' Chicago', 'id': 4842, 'p': 0.0197601318359375}, {'token': ' Los', 'id': 5401, 'p': 0.0185699462890625}], [{'token': ',', 'id': 11, 'p': 0.416015625}, {'token': '.', 'id': 13, 'p': 0.153076171875}, {'token': ' and', 'id': 290, 'p': 0.09283447265625}, {'token': \"'s\", 'id': 338, 'p': 0.0657958984375}, {'token': ' at', 'id': 379, 'p': 0.046661376953125}], [{'token': ' Washington', 'id': 2669, 'p': 0.673828125}, {'token': ' and', 'id': 290, 'p': 0.041778564453125}, {'token': ' WA', 'id': 16400, 'p': 0.0296173095703125}, {'token': ' where', 'id': 810, 'p': 0.0230712890625}, {'token': ' USA', 'id': 4916, 'p': 0.0179595947265625}], [{'token': '.', 'id': 13, 'p': 0.3701171875}, {'token': ',', 'id': 11, 'p': 0.306884765625}, {'token': ' and', 'id': 290, 'p': 0.116455078125}, {'token': ' at', 'id': 379, 'p': 0.050079345703125}, {'token': ' (', 'id': 357, 'p': 0.0152740478515625}], [{'token': ' It', 'id': 632, 'p': 0.351318359375}, {'token': ' The', 'id': 383, 'p': 0.1766357421875}, {'token': '\\n', 'id': 198, 'p': 0.11407470703125}, {'token': ' This', 'id': 770, 'p': 0.0224609375}, {'token': ' In', 'id': 554, 'p': 0.0164337158203125}], [{'token': ' is', 'id': 318, 'p': 0.52392578125}, {'token': ' was', 'id': 373, 'p': 0.1649169921875}, {'token': \"'s\", 'id': 338, 'p': 0.0882568359375}, {'token': ' has', 'id': 468, 'p': 0.0379638671875}, {'token': ' houses', 'id': 7777, 'p': 0.0127105712890625}], [{'token': ' the', 'id': 262, 'p': 0.200927734375}, {'token': ' a', 'id': 257, 'p': 0.12188720703125}, {'token': ' one', 'id': 530, 'p': 0.07867431640625}, {'token': ' located', 'id': 5140, 'p': 0.050811767578125}, {'token': ' home', 'id': 1363, 'p': 0.03082275390625}], [{'token': ' largest', 'id': 4387, 'p': 0.1923828125}, {'token': ' oldest', 'id': 13325, 'p': 0.05511474609375}, {'token': ' second', 'id': 1218, 'p': 0.05511474609375}, {'token': ' tallest', 'id': 38760, 'p': 0.037872314453125}, {'token': ' only', 'id': 691, 'p': 0.033416748046875}], [{'token': ' public', 'id': 1171, 'p': 0.112548828125}, {'token': ' and', 'id': 290, 'p': 0.06414794921875}, {'token': ' of', 'id': 286, 'p': 0.034332275390625}, {'token': ' sculpture', 'id': 26924, 'p': 0.0302886962890625}, {'token': ' building', 'id': 2615, 'p': 0.0267333984375}], [{'token': ' park', 'id': 3952, 'p': 0.2237548828125}, {'token': ' space', 'id': 2272, 'p': 0.15380859375}, {'token': ' art', 'id': 1242, 'p': 0.15380859375}, {'token': ' sculpture', 'id': 26924, 'p': 0.12744140625}, {'token': ' building', 'id': 2615, 'p': 0.0302734375}]]]\n",
      "activations\n",
      "     transformer.h.5 : torch.Size([1, 10, 1024])\n",
      "     transformer.h.6 : torch.Size([1, 10, 1024])\n",
      "     transformer.h.7 : torch.Size([1, 10, 1024])\n",
      "     transformer.h.8 : torch.Size([1, 10, 1024])\n",
      "     transformer.h.9 : torch.Size([1, 10, 1024])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in result.data:\n",
    "    print(\"txt = \", r.generated_text)\n",
    "    print(\"input_tokenized = \", r.input_tokenized)\n",
    "    print(\"answer = \", r.answer)\n",
    "    print('generated_tokens = ', r.generated_tokens)\n",
    "    print(\"activations\")\n",
    "    for layer in r.activations:\n",
    "        print(f\"     {layer} : {torch.tensor(r.activations[layer]).shape}\")\n",
    "\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

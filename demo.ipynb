{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install client library (you may need to restart your kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -e client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This will give you you the `engine` module\n",
    "##### this exposes `engine.get_info`, `engine.submit`, and `engine.retrieve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `engine.get_info` returns a dictionary informing you of the currently loaded model as well as parameters about it, such as layer naming formats which will help you specify the particualar components of the model you want to access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attn_module_name_format': 'model.layers.{}.self_attn',\n",
       " 'layer_name_format': 'model.layers.{}',\n",
       " 'max_seq_length': 2048,\n",
       " 'mlp_module_name_format': 'model.layers.{}.mlp',\n",
       " 'model_name': 'LLaMa-30b',\n",
       " 'n_attn_head': 52,\n",
       " 'n_embd': 6656,\n",
       " 'n_layer': 60}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = engine.get_info()\n",
    "info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `engine.submit(...)` submits your job request to the server. You can see the format and types of the request like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Request',\n",
       " 'type': 'object',\n",
       " 'properties': {'job_id': {'title': 'Job Id', 'type': 'string'},\n",
       "  'prompts': {'title': 'Prompts',\n",
       "   'type': 'array',\n",
       "   'items': {'type': 'string'}},\n",
       "  'max_out_len': {'title': 'Max Out Len', 'default': 20, 'type': 'integer'},\n",
       "  'top_k': {'title': 'Top K', 'default': 5, 'type': 'integer'},\n",
       "  'generate_greedy': {'title': 'Generate Greedy',\n",
       "   'default': True,\n",
       "   'type': 'boolean'},\n",
       "  'activation_requests': {'$ref': '#/definitions/ActivationRequest'}},\n",
       " 'required': ['job_id', 'prompts'],\n",
       " 'definitions': {'ActivationRequest': {'title': 'ActivationRequest',\n",
       "   'type': 'object',\n",
       "   'properties': {'layers': {'title': 'Layers',\n",
       "     'type': 'array',\n",
       "     'items': {'type': 'string'}}}}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.models.submit.Request.schema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Or by visiting our api documentation at [https://ndif.baulab.us/api/docs](https://ndif.baulab.us/api/docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this example request, were going to:\n",
    "\n",
    "<ul>\n",
    "  <li>Process a couple of prompts like, \"Michael Jordan plays the sport of\"</li>\n",
    "  <li>Have ten predicted tokens returned to us per prompt</li>\n",
    "  <li>Have the top five most likely tokens returned to us, not just the top 1</li>\n",
    "  <li>Finally, were going to use the format we recieved from the get_info() function, to specify that we also want the activations at a few layers in the model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 2023-04-15 19:29:07,499 - => Submitting request...\n",
      "INFO: 2023-04-15 19:29:07,506 - => Successfully submitted job 'XrNyvSSGxRVufFYLquyDJL'\n",
      "INFO: 2023-04-15 19:29:07,507 - => Dumped request for job 'XrNyvSSGxRVufFYLquyDJL' to /disk/u/arnab/Projects/engine/jobs/XrNyvSSGxRVufFYLquyDJL\n"
     ]
    }
   ],
   "source": [
    "response = engine.submit(\n",
    "    prompts = [\n",
    "        \"Michael Jordan plays the sport of\",\n",
    "        \"The Space Needle is located in the city of\"\n",
    "    ],\n",
    "    max_new_tokens= 10,\n",
    "    get_answers= True,\n",
    "    top_k = 5,\n",
    "    activation_requests = {\n",
    "        'layers':  [info[\"layer_name_format\"].format(l) for l in range(5, 10)]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The server will recieve our request, and return a status (Which we hope will say that it received our request with no problem), as well as the job id identifying our request. This is loaded into the `engine.models.result.Result` model. The request we submited will be saved to our local `./jobs` directory for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job has been recieved is is waiting approval\n",
      "JobStatus.RECIVED\n",
      "XrNyvSSGxRVufFYLquyDJL\n"
     ]
    }
   ],
   "source": [
    "print(response.description)\n",
    "print(response.status)\n",
    "print(response.job_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now to retrieve what we asked for, we call `engine.retrieve(<job_id>)` using the job_id recieved. This too will return an `engine.models.result.Result` object, and assuming your request has been approved and processed, the `data` field will be populated. \n",
    "\n",
    "##### This result will also be stored to disk in the same directory as the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = engine.retrieve(response.job_id)\n",
    "result.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_text': ModelField(name='generated_text', type=str, required=True),\n",
       " 'input_tokenized': ModelField(name='input_tokenized', type=Optional[list], required=False, default=None),\n",
       " 'generated_tokens': ModelField(name='generated_tokens', type=list, required=True),\n",
       " 'activations': ModelField(name='activations', type=Optional[Mapping[str, list[list[float]]]], required=False, default=None)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.data[0].__fields__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt = <s> Michael Jordan plays the sport of basketball.\n",
      "Michael Jordan is a basketball player.\n",
      "Michael Jordan\n",
      "input_tokenized = [['<s>', 1], ['Michael', 5765], ['Jordan', 18284], ['plays', 13582], ['the', 278], ['sport', 7980], ['of', 310]]\n",
      "generated_tokens = [[{'token': 'basketball', 'id': 20305, 'p': 0.472900390625}, {'token': 'golf', 'id': 29416, 'p': 0.135498046875}, {'token': 'baseball', 'id': 21573, 'p': 0.06109619140625}, {'token': 'k', 'id': 413, 'p': 0.047943115234375}, {'token': 'tennis', 'id': 22556, 'p': 0.025665283203125}], [{'token': '.', 'id': 29889, 'p': 0.1436767578125}, {'token': 'like', 'id': 763, 'p': 0.0987548828125}, {'token': 'with', 'id': 411, 'p': 0.094970703125}, {'token': 'in', 'id': 297, 'p': 0.08648681640625}, {'token': ',', 'id': 29892, 'p': 0.06378173828125}], [{'token': '\\n', 'id': 13, 'p': 0.302978515625}, {'token': 'He', 'id': 940, 'p': 0.2286376953125}, {'token': 'Michael', 'id': 5765, 'p': 0.052642822265625}, {'token': 'His', 'id': 3600, 'p': 0.0240936279296875}, {'token': 'The', 'id': 450, 'p': 0.0228118896484375}], [{'token': 'Michael', 'id': 24083, 'p': 0.1617431640625}, {'token': 'The', 'id': 1576, 'p': 0.0643310546875}, {'token': 'B', 'id': 29933, 'p': 0.0633544921875}, {'token': 'He', 'id': 3868, 'p': 0.04058837890625}, {'token': 'A', 'id': 29909, 'p': 0.0303955078125}], [{'token': 'Jordan', 'id': 18284, 'p': 0.86474609375}, {'token': 'Jeff', 'id': 12208, 'p': 0.054412841796875}, {'token': 'is', 'id': 338, 'p': 0.01453399658203125}, {'token': 'played', 'id': 5318, 'p': 0.005825042724609375}, {'token': 'was', 'id': 471, 'p': 0.005023956298828125}], [{'token': 'is', 'id': 338, 'p': 0.31982421875}, {'token': 'plays', 'id': 13582, 'p': 0.1807861328125}, {'token': 'was', 'id': 471, 'p': 0.1282958984375}, {'token': 'has', 'id': 756, 'p': 0.038818359375}, {'token': '(', 'id': 313, 'p': 0.029754638671875}], [{'token': 'a', 'id': 263, 'p': 0.40185546875}, {'token': 'an', 'id': 385, 'p': 0.1715087890625}, {'token': 'the', 'id': 278, 'p': 0.108154296875}, {'token': 'one', 'id': 697, 'p': 0.050689697265625}, {'token': '', 'id': 29871, 'p': 0.018798828125}], [{'token': 'basketball', 'id': 20305, 'p': 0.1888427734375}, {'token': 'professional', 'id': 10257, 'p': 0.11724853515625}, {'token': 'famous', 'id': 13834, 'p': 0.10760498046875}, {'token': 'retired', 'id': 16528, 'p': 0.062744140625}, {'token': 'former', 'id': 4642, 'p': 0.032318115234375}], [{'token': 'player', 'id': 4847, 'p': 0.87646484375}, {'token': 'legend', 'id': 15983, 'p': 0.02667236328125}, {'token': 'star', 'id': 5810, 'p': 0.0201263427734375}, {'token': 'super', 'id': 2428, 'p': 0.0173492431640625}, {'token': 'er', 'id': 261, 'p': 0.006793975830078125}], [{'token': '.', 'id': 29889, 'p': 0.6015625}, {'token': 'who', 'id': 1058, 'p': 0.1251220703125}, {'token': 'for', 'id': 363, 'p': 0.06341552734375}, {'token': ',', 'id': 29892, 'p': 0.036407470703125}, {'token': 'from', 'id': 515, 'p': 0.03289794921875}], [{'token': '\\n', 'id': 13, 'p': 0.64794921875}, {'token': 'He', 'id': 940, 'p': 0.2071533203125}, {'token': 'Michael', 'id': 5765, 'p': 0.0338134765625}, {'token': '</s>', 'id': 2, 'p': 0.018524169921875}, {'token': 'His', 'id': 3600, 'p': 0.0111541748046875}], [{'token': 'Michael', 'id': 24083, 'p': 0.36962890625}, {'token': 'He', 'id': 3868, 'p': 0.05120849609375}, {'token': 'The', 'id': 1576, 'p': 0.0469970703125}, {'token': 'B', 'id': 29933, 'p': 0.039581298828125}, {'token': 'I', 'id': 29902, 'p': 0.038360595703125}], [{'token': 'Jordan', 'id': 18284, 'p': 0.93798828125}, {'token': 'is', 'id': 338, 'p': 0.0157623291015625}, {'token': 'Jeff', 'id': 12208, 'p': 0.004695892333984375}, {'token': 'plays', 'id': 13582, 'p': 0.004016876220703125}, {'token': 'Jord', 'id': 13783, 'p': 0.0038623809814453125}]]\n",
      "activations\n",
      "     model.layers.5 : torch.Size([19, 6656])\n",
      "     model.layers.6 : torch.Size([19, 6656])\n",
      "     model.layers.7 : torch.Size([19, 6656])\n",
      "     model.layers.8 : torch.Size([19, 6656])\n",
      "     model.layers.9 : torch.Size([19, 6656])\n",
      "\n",
      "txt = <s> The Space Needle is located in the city of Seattle, Washington. It is a tower that\n",
      "input_tokenized = [['<s>', 1], ['The', 450], ['Space', 14121], ['Need', 20768], ['le', 280], ['is', 338], ['located', 5982], ['in', 297], ['the', 278], ['city', 4272], ['of', 310]]\n",
      "generated_tokens = [[{'token': 'Seattle', 'id': 27689, 'p': 0.97802734375}, {'token': 'Se', 'id': 922, 'p': 0.00341796875}, {'token': 'the', 'id': 278, 'p': 0.003391265869140625}, {'token': 'se', 'id': 409, 'p': 0.0022411346435546875}, {'token': 'Sea', 'id': 14070, 'p': 0.0004849433898925781}], [{'token': ',', 'id': 29892, 'p': 0.52392578125}, {'token': 'in', 'id': 297, 'p': 0.2325439453125}, {'token': '.', 'id': 29889, 'p': 0.111572265625}, {'token': 'and', 'id': 322, 'p': 0.067138671875}, {'token': '(', 'id': 313, 'p': 0.00801849365234375}], [{'token': 'Washington', 'id': 7660, 'p': 0.6513671875}, {'token': 'in', 'id': 297, 'p': 0.124267578125}, {'token': 'the', 'id': 278, 'p': 0.03240966796875}, {'token': 'W', 'id': 399, 'p': 0.0260467529296875}, {'token': 'which', 'id': 607, 'p': 0.0229949951171875}], [{'token': '.', 'id': 29889, 'p': 0.433349609375}, {'token': ',', 'id': 29892, 'p': 0.317138671875}, {'token': 'and', 'id': 322, 'p': 0.09368896484375}, {'token': 'in', 'id': 297, 'p': 0.0675048828125}, {'token': 'State', 'id': 4306, 'p': 0.0210723876953125}], [{'token': 'It', 'id': 739, 'p': 0.35400390625}, {'token': 'The', 'id': 450, 'p': 0.2232666015625}, {'token': '\\n', 'id': 13, 'p': 0.08148193359375}, {'token': 'This', 'id': 910, 'p': 0.05963134765625}, {'token': 'Seattle', 'id': 27689, 'p': 0.016693115234375}], [{'token': 'is', 'id': 338, 'p': 0.51806640625}, {'token': 'was', 'id': 471, 'p': 0.34521484375}, {'token': 'has', 'id': 756, 'p': 0.0290069580078125}, {'token': '’', 'id': 30010, 'p': 0.02294921875}, {'token': 'stands', 'id': 15028, 'p': 0.0213775634765625}], [{'token': 'a', 'id': 263, 'p': 0.344482421875}, {'token': 'one', 'id': 697, 'p': 0.1348876953125}, {'token': 'an', 'id': 385, 'p': 0.11907958984375}, {'token': 'the', 'id': 278, 'p': 0.06732177734375}, {'token': '', 'id': 29871, 'p': 0.061767578125}], [{'token': 'tower', 'id': 19372, 'p': 0.35302734375}, {'token': 'major', 'id': 4655, 'p': 0.07696533203125}, {'token': 'land', 'id': 2982, 'p': 0.0648193359375}, {'token': '', 'id': 29871, 'p': 0.06182861328125}, {'token': 'fut', 'id': 3105, 'p': 0.03692626953125}], [{'token': 'that', 'id': 393, 'p': 0.482177734375}, {'token': 'built', 'id': 4240, 'p': 0.06890869140625}, {'token': 'and', 'id': 322, 'p': 0.0504150390625}, {'token': 'ing', 'id': 292, 'p': 0.04888916015625}, {'token': 'with', 'id': 411, 'p': 0.045196533203125}]]\n",
      "activations\n",
      "     model.layers.5 : torch.Size([19, 6656])\n",
      "     model.layers.6 : torch.Size([19, 6656])\n",
      "     model.layers.7 : torch.Size([19, 6656])\n",
      "     model.layers.8 : torch.Size([19, 6656])\n",
      "     model.layers.9 : torch.Size([19, 6656])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in result.data:\n",
    "    print(\"txt =\", r.generated_text)\n",
    "    print(\"input_tokenized =\", r.input_tokenized)\n",
    "    print('generated_tokens =', r.generated_tokens)\n",
    "\n",
    "    if r.activations is not None:\n",
    "        print(\"activations\")\n",
    "        for layer in r.activations:\n",
    "            print(f\"     {layer} : {torch.tensor(r.activations[layer]).shape}\")\n",
    "\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
